{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 기본적인 함수 선언 & 모델 다운로드"
      ],
      "metadata": {
        "id": "mx6s4u4x3wih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab에 필요한 패키지 설치\n",
        "!pip install konlpy rouge-score\n",
        "!apt-get install -y openjdk-11-jdk\n",
        "from google.colab import drive\n",
        "from rouge_score import rouge_scorer\n",
        "import json\n",
        "import requests\n",
        "import random\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from collections import Counter\n",
        "from konlpy.tag import Kkma\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "# Kkma 형태소 분석기 초기화\n",
        "kkma = Kkma()\n",
        "\n",
        "# 형태소 분석 함수\n",
        "def morphological_analysis(sentence):\n",
        "    return kkma.morphs(sentence)\n",
        "\n",
        "# BLEU 점수 계산 함수\n",
        "def calculate_bleu(reference_tokens, candidate_tokens):\n",
        "    return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=SmoothingFunction().method1)\n",
        "\n",
        "# ROUGE-1 점수 계산 함수\n",
        "def calculate_rouge_1(reference_tokens, candidate_tokens):\n",
        "    ref_count = Counter(reference_tokens)\n",
        "    cand_count = Counter(candidate_tokens)\n",
        "    overlap = sum((ref_count & cand_count).values())\n",
        "\n",
        "    precision = overlap / len(candidate_tokens) if len(candidate_tokens) > 0 else 0.0\n",
        "    recall = overlap / len(reference_tokens) if len(reference_tokens) > 0 else 0.0\n",
        "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return precision, recall, f1_score\n",
        "\n",
        "# ROUGE-L 점수 계산 함수\n",
        "def calculate_rouge_l(reference_tokens, candidate_tokens):\n",
        "    def lcs(X, Y):\n",
        "        m = len(X)\n",
        "        n = len(Y)\n",
        "        L = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "        for i in range(m + 1):\n",
        "            for j in range(n + 1):\n",
        "                if i == 0 or j == 0:\n",
        "                    L[i][j] = 0\n",
        "                elif X[i - 1] == Y[j - 1]:\n",
        "                    L[i][j] = L[i - 1][j - 1] + 1\n",
        "                else:\n",
        "                    L[i][j] = max(L[i - 1][j], L[i][j - 1])\n",
        "        return L[m][n]\n",
        "\n",
        "    lcs_length = lcs(reference_tokens, candidate_tokens)\n",
        "\n",
        "    precision = lcs_length / len(candidate_tokens) if len(candidate_tokens) > 0 else 0.0\n",
        "    recall = lcs_length / len(reference_tokens) if len(reference_tokens) > 0 else 0.0\n",
        "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return precision, recall, f1_score\n",
        "#==========================================================================\n",
        "\n",
        "huggingface_token = \"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\"\n",
        "\n",
        "# 모델 및 토크나이저 로드\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    use_auth_token=huggingface_token\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\",\n",
        "    use_auth_token=huggingface_token\n",
        ")\n",
        "\n",
        "#=========================================================================\n",
        "# ROUGE 점수 계산기 초기화=\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "smoothing_function = SmoothingFunction().method1\n",
        "\n",
        "# GitHub의 JSONL 파일 URL\n",
        "url = \"https://raw.githubusercontent.com/beefed-up-geek/HCLT-KACL2024/main/Taeyoon_notebooks/240830_final_data.jsonl\"\n",
        "\n",
        "# JSONL 파일 다운로드\n",
        "response = requests.get(url)\n",
        "lines = response.text.strip().split('\\n')\n",
        "\n",
        "#인공지능의 마지막 대답만 추출하는 함수\n",
        "def extract_last_response(input_text):\n",
        "    start_index = input_text.rfind('[|assistant|]')\n",
        "    if start_index != -1:\n",
        "        return input_text[start_index + len('[|assistant|]'): len(input_text)-len(\"[|endofturn|]\")].strip()\n",
        "    return input_text\n",
        "\n",
        "# 인공지능과 대화하는 함수\n",
        "def chat_with_ai(user_inputs, print_all=False):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"}\n",
        "    ]\n",
        "\n",
        "    for user_input in user_inputs:\n",
        "        if user_input == \"\":\n",
        "            break\n",
        "\n",
        "        # 사용자 입력 추가\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        # 대화 템플릿 적용 및 토큰화\n",
        "        input_ids = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # 모델을 사용해 응답 생성\n",
        "        output = model.generate(\n",
        "            input_ids.to(\"cuda\"),\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            max_new_tokens=512\n",
        "        )\n",
        "\n",
        "        # 인공지능 응답 추출\n",
        "        ai_response = tokenizer.decode(output[0])\n",
        "        ai_response = extract_last_response(ai_response)\n",
        "\n",
        "        # 인공지능 응답을 대화에 추가\n",
        "        messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "\n",
        "    # 전체 대화 내역 출력 여부\n",
        "    if print_all:\n",
        "        for message in messages:\n",
        "            role = message[\"role\"].capitalize()\n",
        "            print(f\"{role}: {message['content']}\\n\")\n",
        "\n",
        "    # 마지막 응답 반환\n",
        "    return messages[-1]['content']\n"
      ],
      "metadata": {
        "id": "OwsZvs4XycJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 여기서 점수 측정용 데이터 n개 랜덤하게 추출\n",
        "만약 데이터를 새로 추출하고 싶거나, 추출하는 데이터의 갯수를 바꾸고 싶으면 <br>**n을 수정하고 다시 실행**"
      ],
      "metadata": {
        "id": "ADcvmIj_1BYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n=20 # 추출할 데이터의 갯수\n",
        "\n",
        "# JSONL 파일 다운로드\n",
        "response = requests.get(url)\n",
        "lines = response.text.strip().split('\\n')\n",
        "\n",
        "# 무작위로 10개의 데이터를 샘플링\n",
        "sampled_data = random.sample(lines, n)\n",
        "\n",
        "# 평가 실행\n",
        "data_pairs = []\n",
        "\n",
        "for line in sampled_data:\n",
        "    data = json.loads(line)\n",
        "    input_data = data['input']\n",
        "    output_data = data['output']\n",
        "\n",
        "    # input을 딕셔너리 형태의 문자열로 변환\n",
        "    input_str = json.dumps(input_data, ensure_ascii=False)\n",
        "\n",
        "    data_pairs.append({\n",
        "        \"id\": data['id'],\n",
        "        \"input\": input_str,\n",
        "        \"output\": output_data\n",
        "    })"
      ],
      "metadata": {
        "id": "Qa-3BTQJ1AF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 여기서 프롬프트 엔지니어링"
      ],
      "metadata": {
        "id": "xprI6iNK0cF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_user_inputs(input_data):\n",
        "    user_inputs = [\n",
        "        f\"{input_data}표에서 highlighted_cells들이 무엇을 나타내고 있는지 알려줘.\",  # 여기부터 5개의 문자열들을 프롬프트 엔지니어링\n",
        "        \"너는 신문 기자고, 표를 참고해서 기사를 쓰고 있어. 사람들에게 한 문장으로 정보를 전달해야해. {og_data_input_str} 이 표에서 highlighted_cells에 대해 한 문장으로 기사를 써줘. 다른 말은 하지 말고 한문장의 기사만 얘기해줘\",\n",
        "        \"\",\n",
        "        \"\",  # 빈 문자열로 대화를 종료\n",
        "        \"\"\n",
        "    ]\n",
        "    return user_inputs\n"
      ],
      "metadata": {
        "id": "vr61k1xdy40N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 바로 점수 측정"
      ],
      "metadata": {
        "id": "Qqrt5oYj0jm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_print_scores(data_pairs):\n",
        "    total_bleu = 0\n",
        "    total_rouge1 = 0\n",
        "    total_rougeL = 0\n",
        "    count = len(data_pairs)\n",
        "\n",
        "    print(\"데이터 ID                      | ROUGE-1 | ROUGE-L | BLEU | 인공지능 대답\")\n",
        "    print(\"-------------------------------+---------+---------+------+---------------\")\n",
        "\n",
        "    for data in data_pairs:\n",
        "        input_data = data['input']\n",
        "        output_data = data['output']\n",
        "        ai_response = chat_with_ai(create_user_inputs(input_data), print_all=False)\n",
        "        ai_response_tokens = morphological_analysis(ai_response)\n",
        "\n",
        "        best_bleu = 0\n",
        "        best_rouge1 = 0\n",
        "        best_rougeL = 0\n",
        "        best_avg = 0  # 이전에 계산한 평균 점수 초기화\n",
        "\n",
        "        for ref in output_data:\n",
        "            ref_tokens = morphological_analysis(ref)\n",
        "\n",
        "            # BLEU 점수 계산\n",
        "            bleu_score = calculate_bleu(ref_tokens, ai_response_tokens)\n",
        "            # ROUGE-1 점수 계산\n",
        "            _, _, rouge1_f1 = calculate_rouge_1(ref_tokens, ai_response_tokens)\n",
        "            # ROUGE-L 점수 계산\n",
        "            _, _, rougeL_f1 = calculate_rouge_l(ref_tokens, ai_response_tokens)\n",
        "\n",
        "            # 새로운 평균 계산\n",
        "            current_avg = (rouge1_f1 + rougeL_f1 + bleu_score) / 3\n",
        "\n",
        "            # 평균 점수가 이전보다 높다면 갱신\n",
        "            if current_avg > best_avg:\n",
        "                best_bleu = bleu_score\n",
        "                best_rouge1 = rouge1_f1\n",
        "                best_rougeL = rougeL_f1\n",
        "                best_avg = current_avg\n",
        "\n",
        "        total_bleu += best_bleu\n",
        "        total_rouge1 += best_rouge1\n",
        "        total_rougeL += best_rougeL\n",
        "\n",
        "        # 결과 출력\n",
        "        print(f\"{data['id']} | {best_rouge1:.4f} |  {best_rougeL:.4f} | {best_bleu:.4f} | {ai_response[:40]}...\")\n",
        "\n",
        "    # 평균 점수 계산 및 출력\n",
        "    avg_bleu = total_bleu / count\n",
        "    avg_rouge1 = total_rouge1 / count\n",
        "    avg_rougeL = total_rougeL / count\n",
        "\n",
        "    print(\"\\n======================================================\")\n",
        "    print(f\"Average ROUGE-1: {avg_rouge1:.4f}\")\n",
        "    print(f\"Average ROUGE-L: {avg_rougeL:.4f}\")\n",
        "    print(f\"Average BLEU: {avg_bleu:.4f}\")\n",
        "\n",
        "# 데이터 평가 및 출력 실행\n",
        "evaluate_and_print_scores(data_pairs)\n",
        "\n"
      ],
      "metadata": {
        "id": "yzpgBlC-0iW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kkma 형태소 분석기 초기화\n",
        "from konlpy.tag import Kkma\n",
        "kkma = Kkma()\n",
        "\n",
        "# 형태소 분석 함수\n",
        "def morphological_analysis(sentence):\n",
        "    tokenized = kkma.morphs(sentence)\n",
        "    return tokenized\n",
        "\n",
        "# ROUGE 점수 계산기 초기화\n",
        "from rouge_score import rouge_scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# 예제 문장\n",
        "ai_response = \"오늘 날씨가 매우 좋다.\"\n",
        "reference_1 = \"오늘 날씨가 좋다.\"\n",
        "reference_2 = \"날씨가 매우 좋다.\"\n",
        "\n",
        "# 형태소 분석 수행\n",
        "ai_response_tokens = morphological_analysis(ai_response)\n",
        "ref_tokens_1 = morphological_analysis(reference_1)\n",
        "ref_tokens_2 = morphological_analysis(reference_2)\n",
        "\n",
        "# 디버깅 함수\n",
        "def debug_rouge_scores(ai_response_tokens, ref_tokens):\n",
        "    # 토큰들을 공백으로 연결하여 문자열로 변환\n",
        "    ai_response_str = \" \".join(ai_response_tokens)\n",
        "    ref_str = \" \".join(ref_tokens)\n",
        "\n",
        "    # ROUGE 점수 계산\n",
        "    rouge_scores = scorer.score(ai_response_str, ref_str)\n",
        "    rouge1_score = rouge_scores['rouge1'].fmeasure\n",
        "    rougeL_score = rouge_scores['rougeL'].fmeasure\n",
        "\n",
        "    print(f\"AI Response Tokens: {ai_response_tokens}\")\n",
        "    print(f\"Reference Tokens: {ref_tokens}\")\n",
        "    print(f\"ROUGE-1 F1 Score: {rouge1_score}\")\n",
        "    print(f\"ROUGE-L F1 Score: {rougeL_score}\")\n",
        "    print(f\"ROUGE-1 Precision: {rouge_scores['rouge1'].precision}\")\n",
        "    print(f\"ROUGE-1 Recall: {rouge_scores['rouge1'].recall}\")\n",
        "    print(f\"ROUGE-L Precision: {rouge_scores['rougeL'].precision}\")\n",
        "    print(f\"ROUGE-L Recall: {rouge_scores['rougeL'].recall}\")\n",
        "    print(\"-----------------------------------------------------\\n\")\n",
        "\n",
        "# 두 개의 예제 참조 문장과 비교\n",
        "print(\"Comparing with reference 1:\")\n",
        "debug_rouge_scores(ai_response_tokens, ref_tokens_1)\n",
        "\n",
        "print(\"Comparing with reference 2:\")\n",
        "debug_rouge_scores(ai_response_tokens, ref_tokens_2)\n"
      ],
      "metadata": {
        "id": "RA-W64U4hLuC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}